{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-10 16:40:54.793202: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-10 16:40:54.950053: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-01-10 16:40:55.557487: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-10 16:40:55.557540: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-10 16:40:55.557548: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading our data, spanish and english corpus and the non breaking prefixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "with open(\"/home/isma/Proyectos/Text_processing/Traductor/Files/europarl-v7.es-en.en\",\n",
    "        mode= \"r\", encoding=\"utf-8\") as f:\n",
    "    europarl_en = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "with open(\"/home/isma/Proyectos/Text_processing/Traductor/Files/europarl-v7.es-en.es\",\n",
    "        mode= \"r\", encoding=\"utf-8\") as f:\n",
    "    europarl_es = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "with open(\"/home/isma/Proyectos/Text_processing/Traductor/Files/P85-Non-Breaking-Prefix.en\",\n",
    "        mode= \"r\", encoding=\"utf-8\") as f:\n",
    "    nonBreaking_en = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "with open(\"/home/isma/Proyectos/Text_processing/Traductor/Files/nonbreaking_prefix.es\",\n",
    "        mode= \"r\", encoding=\"utf-8\") as f:\n",
    "    nonBreaking_es = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inglés:  Resumption of the session\n",
      "I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.\n",
      " \n",
      "\n",
      "Español:  Reanudación del período de sesiones\n",
      "Declaro reanudado el período de sesiones del Parlamento Europeo, interrumpido el viernes 17 de diciembre pasado, y reitero a Sus Señorías mi deseo de que hayan tenido unas buenas vacaciones.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(\"Inglés: \", europarl_en[0:234], \"\\n\\nEspañol: \", europarl_es[0:226])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the non-breaking-prefixes text into a list with every prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ms.', ' ph.', ' prof.', ' sr.', ' st.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "nonBreaking_en = [' ' + pref + '.' for pref in nonBreaking_en.split(\"\\n\")]\n",
    "nonBreaking_en[-10:-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' sra.', ' dr.', ' prof.', ' ing.', ' st.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "nonBreaking_es = [' ' + pref + '.' for pref in nonBreaking_es.split(\"\\n\")]\n",
    "nonBreaking_es[-10:-5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data cleaning using regular expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:15<00:00,  2.72it/s]\n",
      "100%|██████████| 38/38 [00:17<00:00,  2.13it/s]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "corpus_en = europarl_en\n",
    "\n",
    "# Añadimos $$$ (algo que no encontraremos en el corpues) después de los puntos de frases sin fin\n",
    "for prefix in tqdm(nonBreaking_en):\n",
    "    corpus_en = corpus_en.replace(prefix, prefix + '$$$')\n",
    "corpus_en = re.sub(r\"\\.(?=[0-9]|[a-z]|[A-Z])\", \".$$$\", corpus_en)\n",
    "\n",
    "# Eliminamos los marcadores $$$\n",
    "corpus_en = re.sub(r\"\\.\\$\\$\\$\", '', corpus_en)\n",
    "\n",
    "# Eliminamos espacios múltiples\n",
    "corpus_en = re.sub(r\"  +\", \" \", corpus_en)\n",
    "corpus_en = corpus_en.split('\\n')\n",
    "\n",
    "# Realizamos el proceso anterior con el corpus español\n",
    "corpus_es = europarl_es\n",
    "for prefix in tqdm(nonBreaking_es):\n",
    "    corpus_es = corpus_es.replace(prefix, prefix + '$$$')\n",
    "corpus_es = re.sub(r\"\\.(?=[0-9]|[a-z]|[A-Z])\", \".$$$\", corpus_es)\n",
    "corpus_es = re.sub(r\"\\.\\$\\$\\$\", '', corpus_es)\n",
    "corpus_es = re.sub(r\"  +\", \" \", corpus_es)\n",
    "corpus_es = corpus_es.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inglés:  ['Resumption of the session', 'I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.', \"Although, as you will have seen, the dreaded 'millennium bug' failed to materialise, still the people in a number of countries suffered a series of natural disasters that truly were dreadful.\", 'You have requested a debate on this subject in the course of the next few days, during this part-session.', \"In the meantime, I should like to observe a minute' s silence, as a number of Members have requested, on behalf of all the victims concerned, particularly those of the terrible storms, in the various countries of the European Union.\"] \n",
      "\n",
      "Español:  ['Reanudación del período de sesiones', 'Declaro reanudado el período de sesiones del Parlamento Europeo, interrumpido el viernes 17 de diciembre pasado, y reitero a Sus Señorías mi deseo de que hayan tenido unas buenas vacaciones.', 'Como todos han podido comprobar, el gran \"efecto del año 2000\" no se ha producido. En cambio, los ciudadanos de varios de nuestros países han sido víctimas de catástrofes naturales verdaderamente terribles.', 'Sus Señorías han solicitado un debate sobre el tema para los próximos días, en el curso de este período de sesiones.', 'A la espera de que se produzca, de acuerdo con muchos colegas que me lo han pedido, pido que hagamos un minuto de silencio en memoria de todas las víctimas de las tormentas, en los distintos países de la Unión Europea afectados.']\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(\"Inglés: \", corpus_en[0:5], \"\\n\\nEspañol: \", corpus_es[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "resize = True\n",
    "\n",
    "if resize:\n",
    "    corpus_en = corpus_en[0:392]\n",
    "    corpus_es = corpus_es[0:392]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text tokenization, creating the tokenizer (8 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "tokenizer_en = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(corpus_en, target_vocab_size=2**13)\n",
    "\n",
    "tokenizer_es = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(corpus_es, target_vocab_size=2**13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4816, 4816)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "vocab_size_en = tokenizer_en.vocab_size + 2  \n",
    "vocab_size_es = tokenizer_es.vocab_size + 2 \n",
    "\n",
    "vocab_size_en, vocab_size_en"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text tokenization, encoding our corpus to use it as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "inputs = [[vocab_size_en -2] + tokenizer_en.encode(sentence) + [vocab_size_en -1] for sentence in corpus_en]\n",
    "\n",
    "outputs = [[vocab_size_es -2] + tokenizer_es.encode(sentence) + [vocab_size_es -1] for sentence in corpus_es]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing too large sentences (13 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "max_length = 22\n",
    "\n",
    "idx_to_rm = [count for count, sentence in enumerate(inputs) if len(sentence) > max_length]\n",
    "\n",
    "for idx in reversed(idx_to_rm):\n",
    "    del inputs[idx]\n",
    "    del outputs[idx]\n",
    "\n",
    "\n",
    "idx_to_rm = [count for count, sentence in enumerate(outputs) if len(sentence) > max_length]\n",
    "\n",
    "for idx in reversed(idx_to_rm):\n",
    "    del inputs[idx]\n",
    "    del outputs[idx]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Padding sequences for equalize all sequences to the same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    inputs, \n",
    "    value=0, \n",
    "    padding=\"post\", \n",
    "    maxlen=max_length\n",
    "    )\n",
    "\n",
    "outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    outputs, \n",
    "    value=0, \n",
    "    padding=\"post\", \n",
    "    maxlen=max_length\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the dataset with our precleaned data, we'll use cache to speeding up the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-10 16:32:41.069828: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-10 16:32:41.168211: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-10 16:32:41.168434: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-10 16:32:41.170176: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-10 16:32:41.171205: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-10 16:32:41.171377: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-10 16:32:41.171519: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-10 16:32:41.933919: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-10 16:32:41.934415: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-10 16:32:41.934644: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-10 16:32:41.935102: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9083 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:06:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "batch_size = 192\n",
    "buffer_size = 20000\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((inputs, outputs))\n",
    "\n",
    "dataset = dataset.cache()            # Cacheamos el dataset para agilizar el acceso a los datos en el entrenamiento\n",
    "dataset = dataset.shuffle(buffer_size).batch(batch_size)   # Dividir el dataset en batches\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)  # Ajustar caché para que el acceso a los bloques de datos sea más rápido"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construcción de modelo\n",
    "\n",
    "## 1. Encoding posicional"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tratamiento de los espacios vectoriales pares: $$PE_{pos, 2i} = sin(pos/10000^{2i / dmodel})$$\n",
    "tratamiento de los espacios vectoriales impares: $$PE_{pos, 2i + 1} = cos(pos/10000^{2i / dmodel})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "class PositionalEncoding(layers.Layer):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "\n",
    "    def get_angles(self, pos, i, d_model):  # pos : (seq_length, 1), i: (1, d_model)\n",
    "        angles = 1 / np.power( 10000., (2*( i // 2 )) / np.float32(d_model) )\n",
    "        return pos * angles  # (seq_length, d_model)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        seq_length = inputs.shape.as_list()[-2] # max_length\n",
    "        d_model = inputs.shape.as_list()[-1]\n",
    "\n",
    "        angles = self.get_angles(\n",
    "                            pos=np.arange(seq_length)[:, np.newaxis], \n",
    "                            i=np.arange(d_model)[np.newaxis, :],\n",
    "                            d_model=d_model)\n",
    "\n",
    "        angles[:, 0::2] = np.sin(angles[:, 0::2])  # aplicamos sin a las filas impares\n",
    "        angles[:, 1::2] = np.cos(angles[:, 1::2])  # aplicamos cos a las filas impares\n",
    "\n",
    "        pos_encoding = angles[np.newaxis, ...]   # Añadimos una dimensión extra al inicio para poder hacer el tratamiento de batches\n",
    "\n",
    "        return inputs + tf.cast(pos_encoding, tf.float32)   # Combinamos las entradas con el encoding posicional\n",
    "                                                            # que debe convertirse en tensor para poder ser utilizado"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Mecanismo de atención\n",
    "### 2.1 Cálculo de la atención\n",
    "\n",
    "$$Attention(Q, K, V) = softmax \\ \\left( \\dfrac{QK^{T}}{\\sqrt{d_{k}}} \\right) V$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def scaled_dot_product_attention(queries, keys, values, mask):\n",
    "    product = tf.matmul(queries, keys, transpose_b=True)\n",
    "\n",
    "    keys_dim = tf.cast(tf.shape(keys)[-1], tf.float32)\n",
    "    keys_dim_sqrt = tf.math.sqrt(keys_dim)\n",
    "\n",
    "    scaled_product = product / keys_dim_sqrt\n",
    "\n",
    "    if mask is not None:\n",
    "        scaled_product += (mask * -1e9)\n",
    "\n",
    "    softmax_scaled_product = tf.nn.softmax(scaled_product, axis=-1)\n",
    "\n",
    "    attention = tf.matmul(softmax_scaled_product, values)\n",
    "\n",
    "    return attention "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Creación del multihead attention\n",
    "\n",
    "Utilizando la función anterior para el cálculo de la atención, crearemos una función para calcular paralelamente múltiples mecanismos de atención en los diferentes subespacios vectoriales en los que dividimos las entradas para aumentar la complejidad  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "class MultiHeadAttention(layers.Layer):\n",
    "    def __init__(self, nb_projections):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.nb_projections = nb_projections\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # d_model es el tamaño de la dimensión de embedding\n",
    "        self.d_model = input_shape[-1]\n",
    "        \n",
    "        # nos aseguramos de que el tamaño de la dimensión de embedding sea divisible \n",
    "        # entre el número de espacios vectoriales elegidos para el multiHeadAttention\n",
    "        assert self.d_model % self.nb_projections == 0 \n",
    "\n",
    "        # d_projections es el tamaño de cada una de las subdivisiones resultantes de \n",
    "        # dividir nuestra dimensión de embedding en subespacios vectoriales\n",
    "        self.d_projections = self.d_model // self.nb_projections\n",
    "\n",
    "        self.query_lin = layers.Dense(units=self.d_model)\n",
    "        self.key_lin = layers.Dense(units=self.d_model)\n",
    "        self.value_lin = layers.Dense(units=self.d_model)\n",
    "\n",
    "        self.final_lin = layers.Dense(units=self.d_model)\n",
    "\n",
    "\n",
    "    # Para dividir nuestra entrada en los diferentes espacios vectoriales \n",
    "    # para el multihead attention utilizaremos esta función\n",
    "    #\n",
    "    # forma inicial de antes de pasar por la función inputs: \n",
    "    #   - (batch_size, seq_length, d_model)\n",
    "\n",
    "    def split_projetcions(self, inputs, batch_size):\n",
    "        # shape es la variable que utilizaremos para definir la forma de las inputs después \n",
    "        # de ser divididas en subespacios vectoriales\n",
    "        shape = (batch_size, -1, self.nb_projections, self.d_projections)\n",
    "\n",
    "        # forma del input después del cambio: (batch_size, seq_length, nb_projections, d_projections)\n",
    "        splitted_inputs = tf.reshape(inputs, shape=shape)\n",
    "\n",
    "        # forma después de la permutación: (batch_size, nb_projections, seq_length, d_projections)\n",
    "        permute_splitted_inputs = tf.transpose(splitted_inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "        # el objeto retornado está dividido en batches con cada entrada de datos, cada entrada\n",
    "        # de datos está dividido en los subespacios vectoriales, en cada subespacio encontraremos\n",
    "        # la frase (sequence) y por último la porción de la dimensión de embedding del subespacio\n",
    "        return permute_splitted_inputs\n",
    "\n",
    "\n",
    "    # La función call contiene lo necesario para completar el mecanismo de atención, dónde procesamos \n",
    "    # individualmente Q K V en subespacios vectoriales con split_projections, después llamaremos a la\n",
    "    # función que hará el cálculo de la atención, después sólo nos queda devolverle la forma que tenía\n",
    "    # originalmente la entrada y enviarlo a la capa lineal final\n",
    "\n",
    "    def call(self, queries, keys, values, mask):\n",
    "        batch_size = tf.shape(queries)[0]\n",
    "\n",
    "        # llamamos a las capas lineales para cada Q K V\n",
    "        queries = self.query_lin(queries)\n",
    "        keys = self.key_lin(keys)\n",
    "        values = self.value_lin(values)\n",
    "\n",
    "\n",
    "        # utilizamos la función para dividir nuestra entrada de datos en los subespacios vectoriales\n",
    "        queries = self.split_projetcions(inputs=queries, batch_size=batch_size)\n",
    "        keys = self.split_projetcions(inputs=keys, batch_size=batch_size)\n",
    "        values = self.split_projetcions(inputs=values, batch_size=batch_size)\n",
    "\n",
    "\n",
    "        # calculamos la attention en base al procesamiento individual de los subespacios de queries, \n",
    "        # keys y values, después le damos la forma necesaria para ser seguir el proceso, es decir:\n",
    "        #  - (batch_size, nb_projections, seq_length, d_projections)\n",
    "\n",
    "        attention = scaled_dot_product_attention(queries, keys, values, mask)\n",
    "        attention = tf.transpose(attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "\n",
    "        # \"concat_attention\" es la variable que tiene todos los subespacios vectoriales generados para \n",
    "        # ser procesados en conjunto (formando el MultiHeadAttention) siendo enviados a la última capa \n",
    "        # lineal siendo su forma final:\n",
    "        #  - (batch_size, seq_length, d_model)\n",
    "        # es decir, la misma forma que tenía antes del proceso de división en subespacios\n",
    "\n",
    "        concat_attention = tf.reshape(attention, shape=(batch_size, -1, self.d_model))\n",
    "        outputs = self.final_lin(concat_attention)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Encoder\n",
    "### 3.1 Creando la capa encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "class encoderLayer(layers.Layer):\n",
    "\n",
    "    def __init__(self, FC_units, nb_projections, dropout):\n",
    "        super(encoderLayer, self).__init__()\n",
    "\n",
    "        self.FC_units = FC_units\n",
    "        self.nb_projections = nb_projections\n",
    "        self.dropout = dropout\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.d_model = input_shape[-1]\n",
    "\n",
    "        self.multi_head_attention = MultiHeadAttention(self.nb_projections)\n",
    "        self.dropout_1 = layers.Dropout(rate=self.dropout)\n",
    "        self.norm_1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dense_1 = layers.Dense(units=self.FC_units, activation=\"relu\")\n",
    "        self.dense_2 = layers.Dense(units=self.d_model)\n",
    "        self.dropout_2 = layers.Dropout(rate=self.dropout)\n",
    "        self.norm_2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "\n",
    "    def call(self, inputs, mask, training):\n",
    "        attention = self.multi_head_attention(inputs, inputs, inputs, mask)\n",
    "        attention = self.dropout_1(attention, training=training)\n",
    "        attention = self.norm_1(attention + inputs)\n",
    "\n",
    "        outputs = self.dense_1(attention) \n",
    "        outputs = self.dense_2(outputs) \n",
    "        outputs = self.dropout_2(outputs, training=training)\n",
    "        outputs = self.norm_2(outputs + attention) \n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Creamos el encoder utilizando la clase de capa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "class Encoder(layers.Layer):\n",
    "\n",
    "    def __init__(self, nb_layers, FC_units, nb_projections, dropout, vocab_size, d_model, name=\"encoder\"):\n",
    "        super(Encoder, self).__init__(name=name)\n",
    "        \n",
    "        self.nb_layers = nb_layers\n",
    "        self.d_model = d_model\n",
    "\n",
    "        self.embedding = layers.Embedding(vocab_size, d_model)\n",
    "        self.pos_encoding = PositionalEncoding()\n",
    "        self.dropout = layers.Dropout(rate=dropout)\n",
    "        self.encoding_layers = [encoderLayer(FC_units=FC_units, nb_projections=nb_projections, dropout=dropout) for _ in range(nb_layers)]\n",
    "\n",
    "    \n",
    "    def call(self, inputs, mask, training):\n",
    "        outputs = self.embedding(inputs)\n",
    "        outputs *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        outputs = self.pos_encoding(outputs)\n",
    "        outputs = self.dropout(outputs, training)\n",
    "\n",
    "        for i in range(self.nb_layers):\n",
    "            outputs = self.encoding_layers[i](outputs, mask, training) \n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Decoder\n",
    "### 4.1 Clase decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "class decoderLayer(layers.Layer):\n",
    "\n",
    "    def __init__(self, FC_units, nb_projections, dropout):\n",
    "        super(decoderLayer, self).__init__()\n",
    "\n",
    "        self.FC_units = FC_units\n",
    "        self.nb_projections = nb_projections\n",
    "        self.dropout = dropout\n",
    "\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.d_model = input_shape[-1]\n",
    "\n",
    "        self.multi_head_attention_1 = MultiHeadAttention(self.nb_projections)\n",
    "        self.dropout_1 = layers.Dropout(rate=self.dropout)\n",
    "        self.norm_1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.multi_head_attention_2 = MultiHeadAttention(self.nb_projections)\n",
    "        self.dropout_2 = layers.Dropout(rate=self.dropout)\n",
    "        self.norm_2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dense_1 = layers.Dense(units=self.FC_units, activation=\"relu\")\n",
    "        self.dense_2 = layers.Dense(units=self.d_model)\n",
    "        self.dropout_3 = layers.Dropout(rate=self.dropout)\n",
    "        self.norm_3 = layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "\n",
    "    def call(self, inputs, encoder_outputs, mask_1, mask_2, training):\n",
    "        attention = self.multi_head_attention_1(inputs, inputs, inputs, mask_1)\n",
    "        attention = self.dropout_1(attention, training)\n",
    "        attention = self.norm_1(attention + inputs)\n",
    "\n",
    "        attention2 = self.multi_head_attention_2(attention, encoder_outputs, encoder_outputs, mask_2)\n",
    "        attention2 = self.dropout_2(attention2, training)\n",
    "        attention2 = self.norm_2(attention2 + inputs)\n",
    "\n",
    "        outputs = self.dense_1(attention2)\n",
    "        outputs = self.dense_2(outputs)\n",
    "        outputs = self.dropout_3(outputs, training)\n",
    "        outputs = self.norm_3(outputs + attention)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Creamos el decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "class Decoder(layers.Layer):\n",
    "\n",
    "    def __init__(self, nb_layers, FC_units, nb_projections, dropout, vocab_size, d_model, name=\"decoder\"):\n",
    "        super(Decoder, self).__init__(name=name)\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.nb_layers = nb_layers\n",
    "\n",
    "        self.embedding = layers.Embedding(vocab_size, d_model)\n",
    "        self.positional_encoding = PositionalEncoding()\n",
    "        self.dropout = layers.Dropout(rate=dropout)\n",
    "\n",
    "        self.decoder_layers = [decoderLayer(FC_units, nb_projections, dropout) for _ in range(nb_layers)]\n",
    "\n",
    "\n",
    "    def call(self, inputs, encoder_outputs, mask_1, mask_2, training):\n",
    "        outputs = self.embedding(inputs)\n",
    "        outputs *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        outputs = self.positional_encoding(outputs)\n",
    "        outputs = self.dropout(outputs, training)\n",
    "\n",
    "        for i in range(self.nb_layers):\n",
    "            outputs = self.decoder_layers[i](outputs, encoder_outputs, mask_1, mask_2, training)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Juntamos todo para crear el Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, vocab_size_encoder, vocab_size_decoder, d_model, nb_layers, FC_units, nb_projections, dropout, name=\"transformer\"):\n",
    "        super(Transformer, self).__init__(name=name)\n",
    "\n",
    "        self.encoder = Encoder(nb_layers, FC_units, nb_projections, dropout, vocab_size_encoder, d_model)\n",
    "\n",
    "        self.decoder = Decoder(nb_layers, FC_units, nb_projections, dropout, vocab_size_decoder, d_model)\n",
    "\n",
    "        self.last_linear = layers.Dense(units=vocab_size_decoder, name=\"linear_output\")\n",
    "\n",
    "\n",
    "    def create_padding_mask(self, seq): # batch_size, seq_length\n",
    "        mask = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "        return mask[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "\n",
    "    # Para que el modelo no pueda ver palabras futuras, debemos crear una matriz triangular       | 0 | 1 | 1 | 1 |\n",
    "    # de manera que las palabras que queremos ocultar se vayan mostrando una por una según        | 0 | 0 | 1 | 1 |\n",
    "    # el algoritmo vaya avanzando en la secuencia, de manera que en la primero sólo tendremos     | 0 | 0 | 0 | 1 |\n",
    "    # acceso a la primera palabra y iremos desbloqueando las siguientes para evitar que el        | 0 | 0 | 0 | 0 |\n",
    "    # transformer haga trampas y cree conexiones que fuera del entrenamiento resultarían ser \n",
    "    # inútiles. Para crear la matriz utilizaremos la sublibrería de tensorflow linalg (linear algebra) para tratar\n",
    "    # los numeros que se encuentren en la diagonal superior y poder crear la matriz triangular. Las posiciones con \n",
    "    # un 0 serán visibles mientras que las que tengan un 1 tendrán máscara para no ser vistas por el modelo\n",
    "\n",
    "    def create_look_ahead_mask(self, seq):\n",
    "        seq_len = tf.shape(seq)[1]\n",
    "\n",
    "        look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "        return look_ahead_mask\n",
    "\n",
    "\n",
    "    def call(self, encoder_inputs, decoder_inputs, training):\n",
    "        encoder_mask = self.create_padding_mask(encoder_inputs)\n",
    "\n",
    "        # decoder_mask_1                                                                            [8, 0, 35, 74, 0, 12]\n",
    "\n",
    "        # combinamos las masks de cada secuencia con la look ahead mask para evitar que el        | 0 | 1 | 1 | 1 | 1 | 1 | \n",
    "        # modelo vea palabras futuras, de manera que con una secuencia de cómo la siguiente:      | 0 | 1 | 1 | 1 | 1 | 1 |\n",
    "        # - [8, 0, 35, 74, 0, 12] nosotros obtendríamos la siguiente matriz en decoder:           | 0 | 1 | 0 | 1 | 1 | 1 |\n",
    "        #                                                                                         | 0 | 1 | 0 | 0 | 1 | 1 |\n",
    "        #                                                                                         | 0 | 1 | 0 | 0 | 1 | 1 |\n",
    "        #                                                                                         | 0 | 1 | 0 | 0 | 1 | 0 |\n",
    "        decoder_mask_1 = tf.maximum(\n",
    "            self.create_padding_mask(decoder_inputs),\n",
    "            self.create_look_ahead_mask(decoder_inputs) )\n",
    "\n",
    "        decoder_mask_2 = self.create_padding_mask(encoder_inputs)\n",
    "\n",
    "        encoder_outputs = self.encoder(encoder_inputs, encoder_mask, training)\n",
    "\n",
    "        decoder_outputs = self.decoder(decoder_inputs, encoder_outputs, decoder_mask_1, decoder_mask_2, training)\n",
    "\n",
    "        outputs = self.last_linear(decoder_outputs)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fase de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Hiperparámetros\n",
    "\n",
    "d_model = 512\n",
    "nb_layers = 6\n",
    "FC_units = 1024\n",
    "nb_projections = 8\n",
    "dropout_rate = 0.15\n",
    "\n",
    "transformer = Transformer(vocab_size_encoder=vocab_size_en,\n",
    "                          vocab_size_decoder=vocab_size_es,\n",
    "                          d_model=d_model,\n",
    "                          nb_layers=nb_layers, \n",
    "                          FC_units=FC_units,\n",
    "                          nb_projections=nb_projections,\n",
    "                          dropout=dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Losses\n",
    "\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction=\"none\")\n",
    "\n",
    "# From_logits=True, las salidas ya vienen en números salidos de una función softmax listos para calcular la loss\n",
    "# Reduction=\"none\", las pérdidas con se calculan haciendo la media del batch completo sinó cada muestra del batch individualmente \n",
    "\n",
    "# usaremos nuestra propia función de pérdida\n",
    "\n",
    "def loss_function(target, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(target, 0))\n",
    "    loss_ = loss_object(target, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)\n",
    "\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name=\"train_loss\")\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name=\"train_accuracy\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$learning\\_ rate = d_{model}^{-0.5} \\cdot min(step\\_ num^{-0.5}, \\ step\\_ num \\cdot warmup\\_ steps^{-1.5})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Learning rate schedule nos permite jugar con la variable step para variar el learning rate en función de step\n",
    "\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "    def __init__(self, d_model, warmup_steps=3000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)  # rational sqrt, (step_num^{-0.5})\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "\n",
    "\n",
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Último checkpoint restaurado!!\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "checkpoint_path = \"./ckpt/max_l{}\".format(max_length)\n",
    "\n",
    "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
    "                           optimizer=optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print(\"Último checkpoint restaurado!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"encoder\" \"                 f\"(type Encoder).\n\nIn this `tf.Variable` creation, the initial value's shape ((8198, 512)) is not compatible with the explicitly supplied `shape` argument ((4816, 512)).\n\nCall arguments received by layer \"encoder\" \"                 f\"(type Encoder):\n  • inputs=tf.Tensor(shape=(192, 18), dtype=int32)\n  • mask=tf.Tensor(shape=(192, 1, 1, 18), dtype=float32)\n  • training=True",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [30], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m decoder_outputs_real \u001b[39m=\u001b[39m targets[:, \u001b[39m1\u001b[39m:]\n\u001b[1;32m     26\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mGradientTape() \u001b[39mas\u001b[39;00m tape:\n\u001b[0;32m---> 27\u001b[0m     predictions \u001b[39m=\u001b[39m transformer(encoder_inputs, decoder_inputs, \u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     28\u001b[0m     loss \u001b[39m=\u001b[39m loss_function(decoder_outputs_real, predictions)\n\u001b[1;32m     30\u001b[0m gradients \u001b[39m=\u001b[39m tape\u001b[39m.\u001b[39mgradient(loss, transformer\u001b[39m.\u001b[39mtrainable_variables)\n",
      "File \u001b[0;32m~/PythonI/commonUseEnv/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[0;32mIn [25], line 50\u001b[0m, in \u001b[0;36mTransformer.call\u001b[0;34m(self, encoder_inputs, decoder_inputs, training)\u001b[0m\n\u001b[1;32m     44\u001b[0m decoder_mask_1 \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mmaximum(\n\u001b[1;32m     45\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_padding_mask(decoder_inputs),\n\u001b[1;32m     46\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_look_ahead_mask(decoder_inputs) )\n\u001b[1;32m     48\u001b[0m decoder_mask_2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_padding_mask(encoder_inputs)\n\u001b[0;32m---> 50\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(encoder_inputs, encoder_mask, training)\n\u001b[1;32m     52\u001b[0m decoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder(decoder_inputs, encoder_outputs, decoder_mask_1, decoder_mask_2, training)\n\u001b[1;32m     54\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlast_linear(decoder_outputs)\n",
      "Cell \u001b[0;32mIn [22], line 16\u001b[0m, in \u001b[0;36mEncoder.call\u001b[0;34m(self, inputs, mask, training)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\u001b[39mself\u001b[39m, inputs, mask, training):\n\u001b[0;32m---> 16\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membedding(inputs)\n\u001b[1;32m     17\u001b[0m     outputs \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mmath\u001b[39m.\u001b[39msqrt(tf\u001b[39m.\u001b[39mcast(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39md_model, tf\u001b[39m.\u001b[39mfloat32))\n\u001b[1;32m     18\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpos_encoding(outputs)\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"encoder\" \"                 f\"(type Encoder).\n\nIn this `tf.Variable` creation, the initial value's shape ((8198, 512)) is not compatible with the explicitly supplied `shape` argument ((4816, 512)).\n\nCall arguments received by layer \"encoder\" \"                 f\"(type Encoder):\n  • inputs=tf.Tensor(shape=(192, 18), dtype=int32)\n  • mask=tf.Tensor(shape=(192, 1, 1, 18), dtype=float32)\n  • training=True"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output # For Jupyter Notebook\n",
    "\n",
    "epochs = 20 \n",
    "lista_total = []\n",
    "proggress = False\n",
    "total = len(dataset)\n",
    "count = 0\n",
    "count_batch = 0\n",
    "sections = 40\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    if proggress:\n",
    "        lista_total.append(proggress)\n",
    "    lista_total.append(\"epoch: {}\".format(epoch))\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "\n",
    "    for (batch, (encoder_inputs, targets)) in enumerate(dataset):\n",
    "        \n",
    "        decoder_inputs = targets[:, :-1]\n",
    "        decoder_outputs_real = targets[:, 1:]\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = transformer(encoder_inputs, decoder_inputs, True)\n",
    "            loss = loss_function(decoder_outputs_real, predictions)\n",
    "        \n",
    "        gradients = tape.gradient(loss, transformer.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, transformer.trainable_variables)) \n",
    "\n",
    "        train_loss(loss)\n",
    "        train_accuracy(decoder_outputs_real, predictions)\n",
    "\n",
    "        #if batch % 20 == 0:\n",
    "        #    print(\"Epoch: {}. Lote: {}. Pérdidas: {:.4f}. Precisión {:.4f}\".format(epoch+1, batch, train_loss.result(), train_accuracy.result()) ) \n",
    "\n",
    "        count_batch+=1\n",
    "        \n",
    "        if count_batch > (total / sections):\n",
    "            clear_output(wait=True) # For Jupyter Notebook\n",
    "            #os.system('clear')\n",
    "\n",
    "            processed = total/sections * (count+1)\n",
    "            proggress = \"[Total: {} / {} batches / {} processed]\\t[loss: {:.4f}, accuracy: {:.4f}]\\t\".format(int(total), int(processed), int(processed)*batch_size, \n",
    "                                                                                                             train_loss.result(), train_accuracy.result()\n",
    "                                                                                                             ) + \"\\n\" + \"|\"*(count+1)\n",
    "\n",
    "            for line in lista_total:\n",
    "                print(line)\n",
    "            print(proggress)\n",
    "\n",
    "            count+=1\n",
    "            count_batch = 0\n",
    "\n",
    "    ckpt_save_path = ckpt_manager.save()\n",
    "    count = 0\n",
    "\n",
    "    print(\"Guardando checkpoint para epoch {} en {}\".format(epoch + 1, ckpt_save_path))\n",
    "    print(\"Tiempo total de epoch {} sec\".format(time.time() - start))\n",
    "\n",
    "    count_batch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def evaluate(input_sentence):\n",
    "    input_sentence = \\\n",
    "        [vocab_size_en-2] + tokenizer_en.encode(input_sentence) + [vocab_size_en-1]\n",
    "    \n",
    "    encoder_inputs = tf.expand_dims(input_sentence, axis=0)\n",
    "\n",
    "    output = tf.expand_dims([vocab_size_es-2], axis=0)\n",
    "\n",
    "    for _ in range(max_length):\n",
    "        predictions = transformer(encoder_inputs, output, False)   # predictions shape: (1, seq_length, vocab_size_es)\n",
    "\n",
    "        prediction = predictions[:, -1:, :]                         # nos quedamos con:\n",
    "                                                                   #  - todas las secuencias (en éste caso sólo 1)\n",
    "                                                                   #  - la última palabra usada del input\n",
    "                                                                   #  - el vector con todas las palabras en español y la probabilidad de cada una\n",
    "\n",
    "        # tomando el vector de palabras españolas, obtenemos el id de la que más probabilidad ha obtenido\n",
    "        predicted_id = tf.cast(tf.argmax(prediction, axis=-1), tf.int32)   \n",
    "\n",
    "        # la frase ha terminado, no hay nada más que decir\n",
    "        if predicted_id == vocab_size_es-1:\n",
    "            return tf.squeeze(output, axis=0)   # eliminamos la primera dimensión, la del batch, para quedarnos únicamente con la predicción\n",
    "\n",
    "        output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "    # la frase ha terminado porque hemos alcanzado max_length\n",
    "    return tf.squeeze(output, axis=0)\n",
    "\n",
    "\n",
    "# la función evaluate nos devuelve los tokens de las palabras en castellano por lo que tenemos que traducirlas\n",
    "\n",
    "def translate(sentence):\n",
    "    # ya no es necesario usar tensores, por lo que ahora la trabajamos con numpy\n",
    "    output = evaluate(sentence).numpy()\n",
    "\n",
    "    predicted_sentence = tokenizer_es.decode(\n",
    "        [i for i in output if i < vocab_size_es-2]\n",
    "    )\n",
    "\n",
    "    print(\"Entrada: {}\".format(sentence))\n",
    "    print(\"Salida: {}\".format(predicted_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrada: This is a problem we have to solve.\n",
      "Salida: Es un problema que tenemos que resolver.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "translate(\"This is a problem we have to solve.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrada: This is a really powerful tool!\n",
      "Traducción predicha: ¡Es una evidencia muy importante!\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "translate(\"This is a really powerful tool!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrada: Reader feedback, whether positive or negative, five stars or one star, will encourage the product owner to make improvements.\n",
      "Salida: Puede ser muy eficaz si se produce un tratamiento más seguro de residuos.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "translate(\"Reader feedback, whether positive or negative, five stars or one star, will encourage the product owner to make improvements.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrada: Try it again. Fail again. Fail better. Vuelve a intentarlo. Fracasa de nuevo. Fracasa mejor. \n",
      "Traducción predicha: Discreputación de un hombre que se ha convertido en un hombre de bocao, pero no me parece que sea un error de traducción.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "translate(\"Try it again. Fail again. Fail better. Vuelve a intentarlo. Fracasa de nuevo. Fracasa mejor. \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f41f80dd5e5e329c215f6b6e4fcb487fc0c512ad7bf9118874dd7db84e187ff4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
